{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC\n",
    "\n",
    "## Working with Word2Vec with Gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "- Visualize word vectorization\n",
    "- Prepare gensim environment\n",
    "- Fit word2vec models\n",
    "- Interpret latent variables/vectors\n",
    "- Find similar words and word pairs\n",
    "- Use externally-trained matrices of latent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been working with a number of techniques and tools that help us navigate the world of NLP. For example, we have CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>above</th>\n",
       "      <th>above all</th>\n",
       "      <th>all</th>\n",
       "      <th>all to</th>\n",
       "      <th>be</th>\n",
       "      <th>be true</th>\n",
       "      <th>come</th>\n",
       "      <th>come to</th>\n",
       "      <th>denmark</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>the state</th>\n",
       "      <th>thine</th>\n",
       "      <th>thine own</th>\n",
       "      <th>this</th>\n",
       "      <th>this above</th>\n",
       "      <th>to</th>\n",
       "      <th>to thine</th>\n",
       "      <th>to this</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   above  above all  all  all to  be  be true  come  come to  denmark  in  \\\n",
       "0      0          0    0       0   0        0     1        1        0   0   \n",
       "1      1          1    1       1   1        1     0        0        0   0   \n",
       "2      0          0    0       0   0        0     0        0        1   1   \n",
       "\n",
       "   ...   the  the state  thine  thine own  this  this above  to  to thine  \\\n",
       "0  ...     0          0      0          0     1           0   1         0   \n",
       "1  ...     0          0      1          1     1           1   1         1   \n",
       "2  ...     1          1      0          0     0           0   0         0   \n",
       "\n",
       "   to this  true  \n",
       "0        1     0  \n",
       "1        0     1  \n",
       "2        0     0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = ['That is should come to this!', 'This above all: to thine own self be true.', 'Something is rotten in the state of Denmark.']\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "vectorizer.fit(text)\n",
    "x = vectorizer.transform(text)\n",
    "x_back = x.toarray()\n",
    "\n",
    "pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">An adverse trait about the Bag of Words model: Word context and semantic meaning does not play a role.\n",
    "\n",
    ">But then came Word2Vec!\n",
    "\n",
    ">We will see that with Word2Vec, context does play a role and it can decipher relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGuxJREFUeJzt3XtwVfW99/H31yRi0BAUokhICAJS0cGiARWh0Tk8hoDiZQShiAUv6DmCrbYcURyltKejUqZ9tPZQaC2czih6lGKEVo6Xchk5qBGQimMsgiBJLXcq5Rr4Pn9kN08Igb1CdvZOfnxeM8ysy2+v9VnbvT8u1tp7Y+6OiIiE5bRUBxARkcRTuYuIBEjlLiISIJW7iEiAVO4iIgFSuYuIBEjlLiISIJW7iEiAVO4iIgFKT9WO27dv7wUFBanavYhIi/Thhx9uc/eceONSVu4FBQWUlZWlavciIi2SmW2MMk6XZUREAqRyFxEJkMpdRCRAKncRkQCp3EVEAqRyFxEJkMpdRCRAKncRkQCp3EVEAhS33M3seTPbYmYfxxnXx8wOm9mtiYsnIiInI8qZ+2xg0IkGmFka8BSwKAGZRESkkeKWu7svBXbEGTYBeBXYkohQIiLSOI2+5m5mucDNwIzGxxERkURIxA3VnwMPu/vheAPNbJyZlZlZ2datWxOwaxERqU8ifvK3EJhrZgDtgcFmVuXu8+sOdPeZwEyAwsJCT8C+RUSkHo0ud3fv8s9pM5sNLKiv2EVEJHnilruZvQhcA7Q3s83AE0AGgLvrOruISDMUt9zdfWTUjbn7mEalERGRhNA3VEVEAqRyFxEJkMpdRCRAKncRkQCp3EVEAqRyFxEJkMpdRCRAKncRkQCp3EVEAqRyFxEJkMpdRCRAKncRkQCp3EVEAqRyFxEJkMpdRCRAKncRkQCp3EVEAqRyFxEJkMpdRCRAKncRkQDFLXcze97MtpjZx8dZP8rM1sT+LDezSxMfU0REGiLKmftsYNAJ1m8Aity9F/AjYGYCcomISCOkxxvg7kvNrOAE65fXml0BdGp8LBERaYxEX3O/C/hjgrcpIiINFPfMPSozu5bqcu9/gjHjgHEA+fn5idq1iIjUkZAzdzPrBfwauNHdtx9vnLvPdPdCdy/MyclJxK5FRKQejS53M8sH5gGj3f2zxkcSEZHGintZxsxeBK4B2pvZZuAJIAPA3WcAjwPtgF+aGUCVuxc2VWAREYkvyqdlRsZZfzdwd8ISiYhIo+kbqiIiAVK5i4gESOUuIhIglbuISIBU7iIiAVK5i4gESOUuIhIglbuISIBU7iIiAVK5i4gESOUuIhIglbuISIBU7iIiAVK5i4gESOUuIhIglbuISIBU7iIiAVK5i4gESOUuIhIglbuISIDilruZPW9mW8zs4+OsNzN7xszWmdkaM7ss8TFFRKQhopy5zwYGnWB9CdA99mcc8J+NjyUiIo0Rt9zdfSmw4wRDbgT+y6utANqa2fmJCigiIg2XiGvuucCXteY3x5aJiEiKJKLcrZ5lXu9As3FmVmZmZVu3bk3ArkVEpD6JKPfNQF6t+U5AZX0D3X2muxe6e2FOTk4Cdi0iIvVJRLmXAnfEPjVzJbDb3f+agO2KiMhJSo83wMxeBK4B2pvZZuAJIAPA3WcAfwAGA+uAvcDYpgorIiLRxC13dx8ZZ70D9ycskYiINJq+oSoiEiCVu4hIgFTuIiIBUrmLiARI5S4iEiCVu4hIgFTuIiIBUrmLiARI5S4iEiCVu4hIgFTuIiIBUrmLiARI5S4iEiCVu4hIgFTu0uwUFBTw1ltvHbP84osvZvHixckPJNICxf09d5HmYu3atamOINJi6MxdRCRAKndp1j799FO6dOnC3Llzj7pcM2XKFIYPH84dd9xBVlYWF198MWVlZTWPW7lyJb179yYrK4thw4Zx22238dhjj6XqMESSTuUuzdbKlSu57rrrePbZZxkxYsQx60tLSxkxYgS7du1i6NChjB8/HoCDBw9y8803M2bMGHbs2MHIkSP5/e9/n+z4IimlcpdmadmyZQwdOpQ5c+Zw/fXX1zumf//+DB48mLS0NEaPHs1HH30EwIoVK6iqquKBBx4gIyODW265hb59+yYzvkjKRSp3MxtkZuVmts7MJtWzPt/M/mRmq8xsjZkNTnxUOZXMmDGDfv36ce211x53TIcOHWqmW7duzf79+6mqqqKyspLc3FzMrGZ9Xl5ek+YVaW7ilruZpQHPASVAT2CkmfWsM+wx4GV37w2MAH6Z6KAStvmrKrj6yXfoMmkhX+3ez9h//w82bdrEgw8+2OBtnX/++VRUVODuNcu+/PLLRMYVafainLn3Bda5+3p3PwjMBW6sM8aBNrHpbKAycREldPNXVfDIvD9TsWsfDlQdcV5YuZUJTz/P0qVLmTTpmL8sntBVV11FWloav/jFL6iqquK1117j/fffb5rwIs1UlM+55wK1T3s2A1fUGTMF+B8zmwCcCQxMSDo5JUxbVM6+Q4ePWnbg8BF+ufwr3nzzTa699loyMjIib+/0009n3rx53H333TzyyCOUlJRw/fXX06pVq0RHF2m2rPZfXesdYDYMKHb3u2Pzo4G+7j6h1piHYtuabmZXAb8BLnH3I3W2NQ4YB5Cfn3/5xo0bE3ow0jJ1mbSQ+l6FBmx4ckhC9nHFFVdw3333MXbs2IRsTyRVzOxDdy+MNy7KZZnNQO27UZ049rLLXcDLAO7+v8AZQPu6G3L3me5e6O6FOTk5EXYtp4KObTMbtDyKJUuW8NVXX1FVVcWcOXNYs2YNgwYNOuntibQ0Ucr9A6C7mXUxs9OpvmFaWmfMJuBfAMzsIqrLfWsig0q4Jhb3IDMj7ahlmRlpTCzucdLbLC8v59JLLyU7O5vp06fzyiuvcP755zc2qkiLEfeyDEDso40/B9KA5939P8xsKlDm7qWxT8/MAs6i+ubqv7v7/5xom4WFhV77G4Vyapu/qoJpi8qp3LWPjm0zmVjcg5t656Y6lkizE/WyTKRybwoqdxGRhkvkNXcREWlhVO4iIgFSuYuIBEjlLiISIJW7iEiAVO4iIgFSuYuIBEjlLiISIJW7iEiAVO4iIgFSuYuIBEjlLiISIJW7iEiAVO4iIgFSuYuIBEjlLiISIJW7iEiAVO4iCbBq1Souu+wysrKyuO222xgxYgSPPfYYs2fPpn///keNNTPWrVsHwIEDB/jBD35Afn4+5513Hvfddx/79u2rGbtgwQK++c1v0rZtW/r168eaNWtq1hUUFPDTn/6UXr16kZ2dzW233cb+/fuTc8DS7KncRRrp4MGD3HTTTYwePZodO3YwbNgwXn311UiPffjhh/nss89YvXo169ato6KigqlTpwKwcuVK7rzzTn71q1+xfft27r33XoYOHcqBAwdqHv/yyy/zxhtvsGHDBtasWcPs2bOb4hClBVK5izTSihUrOHToEN/73vfIyMjg1ltvpU+fPnEf5+7MmjWLn/3sZ5xzzjlkZWXx6KOPMnfuXABmzZrFvffeyxVXXEFaWhrf+c53aNWqFStWrKjZxgMPPEDHjh0555xzuOGGG1i9enWTHae0LOlRBpnZIOD/AmnAr939yXrGDAemAA585O7fTmBOkWarsrKS3NxczKxmWefOneM+buvWrezdu5fLL7+8Zpm7c/jwYQA2btzInDlzePbZZ2vWHzx4kMrKypr5Dh061Ey3bt36qHVyaotb7maWBjwH/B9gM/CBmZW6+ye1xnQHHgGudvedZnZuUwUWaS7mr6pg2qJy1q/5gu3lG/j9ys3cfFknADZt2kTXrl0588wz2bt3b81jvvrqq5rp9u3bk5mZydq1a8nNzT1m+3l5eUyePJnJkyc3/cFIcKJclukLrHP39e5+EJgL3FhnzD3Ac+6+E8DdtyQ2pkjzMn9VBY/M+zMVu/Zxeu43OMJp3PfIj3n1g43MmzeP999/H4BLL72UtWvXsnr1avbv38+UKVNqtnHaaadxzz338OCDD7JlS/VbpqKigkWLFgFwzz33MGPGDN577z3cnX/84x8sXLiQr7/+OunHKy1PlHLPBb6sNb85tqy2C4ELzexdM1sRu4wjEqxpi8rZd6j68omlZZBz86PsXP0mw/tfxEsvvcQtt9wCwIUXXsjjjz/OwIED6d69+zGfnHnqqafo1q0bV155JW3atGHgwIGUl5cDUFhYyKxZsxg/fjxnn3023bp10w1Ticzc/cQDzIYBxe5+d2x+NNDX3SfUGrMAOAQMBzoBy4BL3H1XnW2NA8YB5OfnX75x48YEHopI8nSZtJD63jkGbHhyCGPGjKFTp078+Mc/TnY0CZyZfejuhfHGRTlz3wzk1ZrvBNS9a7MZeM3dD7n7BqAc6F53Q+4+090L3b0wJycnwq5FmqeObTMbtFwk2aKU+wdAdzPrYmanAyOA0jpj5gPXAphZe6ov06xPZFCR5mRicQ8yM9KOWpaZkcbE4h4pSiRytLiflnH3KjMbDyyi+qOQz7v7WjObCpS5e2ls3XVm9glwGJjo7tubMrhIKt3Uu/q207RF5VTu2kfHtplMLO5Rs1zXxiXV4l5zbyqFhYVeVlaWkn2LiLRUibzmLiIiLYzKXUQkQCp3EZEAqdxFRAKkchcRCZDKXUQkQCp3EZEAqdxFRAKkchcRCZDKXUQkQCp3EZEAqdxFRAKkchcRCZDKXUQkQCp3EZEAqdxFRAKkchcRCZDKvYEKCgqYNm0avXr14swzz+Suu+7ib3/7GyUlJWRlZTFw4EB27twJwLBhw+jQoQPZ2dl861vfYu3atTXbGTNmDPfffz9DhgwhKyuLK664gs8//zxVhyUigVG5n4RXX32VN998k88++4zXX3+dkpISfvKTn7Bt2zaOHDnCM888A0BJSQl/+ctf2LJlC5dddhmjRo06ajsvvvgiTzzxBDt37qRbt25Mnjw5FYcjIgGK+w9ky7EmTJjAeeedB8CAAQM499xz6d27NwA333wzb7/9NgB33nlnzWOmTJnC2Wefze7du8nOzgbglltuoW/fvgCMGjWKhx56KJmHISIBi3TmbmaDzKzczNaZ2aQTjLvVzNzM4v7jrS3ZP4sdIDMz85j5PXv2cPjwYSZNmkTXrl1p06YNBQUFAGzbtq1mbIcOHWqmW7duzZ49e5o+vIicEuKWu5mlAc8BJUBPYKSZ9axnXBbwAPBeokOm2vxVFVz95Dt0mbSQr3bv59112+I+5oUXXuC1117jrbfeYvfu3XzxxRcAuHsTpxURiXbm3hdY5+7r3f0gMBe4sZ5xPwKeBvYnMF/KzV9VwSPz/kzFrn04UHXE+c2yDcxfVXHCx3399de0atWKdu3asXfvXh599NHkBBYRIVq55wJf1prfHFtWw8x6A3nuviCB2ZqFaYvK2Xfo8FHLDhw+wrRF5Sd83B133EHnzp3Jzc2lZ8+eXHnllU0ZU0TkKBbvMoGZDQOK3f3u2PxooK+7T4jNnwa8A4xx9y/MbDHwA3cvq2db44BxAPn5+Zdv3LgxkcfSJLpMWkh9z5ABG54ckuw4InKKM7MP3T3ufc0oZ+6bgbxa852AylrzWcAlwGIz+wK4Eiit76aqu89090J3L8zJyYmw69Tr2DazQctFRJqDKOX+AdDdzLqY2enACKD0nyvdfbe7t3f3AncvAFYAQ+s7c2+JJhb3IDMj7ahlmRlpTCzukaJEIiLxxf2cu7tXmdl4YBGQBjzv7mvNbCpQ5u6lJ95Cy3ZT7+rbC9MWlVO5ax8d22YysbhHzXIRkeYo7jX3plJYWOhlZUGc3IuIJE0ir7mLiEgLo3IXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIP3G9/+1tuuOGGmvlu3boxfPjwmvm8vDxWr17N8uXL6dOnD9nZ2fTp04fly5fXjLnmmmt47LHH6NevH2eddRY33HAD27dvZ9SoUbRp04Y+ffrwxRdf1Iz/7ne/S15eHm3atOHyyy9n2bJlNeumTJnC8OHDueOOO8jKyuLiiy9G/yKXSOKp3ANXVFTEsmXLOHLkCH/96185dOgQ7777LgDr169nz5495OfnM2TIEB544AG2b9/OQw89xJAhQ9i+fXvNdubOncvvfvc7Kioq+Pzzz7nqqqsYO3YsO3bs4KKLLuKHP/xhzdg+ffqwevVqduzYwbe//W2GDRvG/v37a9aXlpYyYsQIdu3axdChQxk/fnzynhCRU4TKPXAXXHABWVlZrF69miVLllBcXExubi6ffvopS5YsYcCAASxcuJDu3bszevRo0tPTGTlyJN/4xjd4/fXXa7YzduxYunbtSnZ2NiUlJXTt2pWBAweSnp7OsGHDWLVqVc3Y22+/nXbt2pGens73v/99Dhw4QHl5ec36/v37M3jwYNLS0hg9ejQfffRRUp8TkVNBpHI3s0FmVm5m68xsUj3rHzKzT8xsjZm9bWadEx9VTlZRURGLFy9m6dKlFBUVcc0117BkyRKWLFlCUVERlZWVdO589H+yzp07U1FRUTN/3nnn1UxnZmYeM79nz56a+enTp3PRRReRnZ1N27Zt2b17N9u2batZ36FDh5rp1q1bs3//fqqqqhJ6zCKnurjlbmZpwHNACdATGGlmPesMWwUUunsv4BXg6UQHlejmr6rg6iffocukhVz95Du06dKLxYsXs2zZMoqKiigqKjqq3Dt27MjGjRuP2samTZvIzc1t8L6XLVvGU089xcsvv8zOnTvZtWsX2dnZuHuiDk9EIohy5t4XWOfu6939IDAXuLH2AHf/k7vvjc2uADolNqZENX9VBY/M+zMVu/bhQMWufSzafg5vvv0O+/bto1OnTgwYMIA33niD7du307t3bwYPHsxnn33GCy+8QFVVFS+99BKffPIJ119/fYP3//XXX5Oenk5OTg5VVVVMnTqVv//974k/UBE5oSjlngt8WWt+c2zZ8dwF/LExoeTkTVtUzr5Dh49adrjN+RxOa8WAAQMAaNOmDRdccAFXX301aWlptGvXjgULFjB9+nTatWvH008/zYIFC2jfvn2D919cXExJSQkXXnghnTt35owzziAvLy8hxyYi0Vm8vy6b2TCg2N3vjs2PBvq6+4R6xt4OjAeK3P1APevHAeMA8vPzL697KUAar8ukhdT3X9SADU8OSXYcEUkwM/vQ3QvjjYty5r4ZqH3q1QmorGeHA4HJwND6ih3A3We6e6G7F+bk5ETYtTRUx7aZDVouImGKUu4fAN3NrIuZnQ6MAEprDzCz3sCvqC72LYmPKVFNLO5BZkbaUcsyM9KYWNwjRYlEJBXS4w1w9yozGw8sAtKA5919rZlNBcrcvRSYBpwF/LeZAWxy96FNmFuO46be1bdDpi0qp3LXPjq2zWRicY+a5SJyaoh7zb2pFBYWur52LiLSMIm85i4iIi2Myl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCpHIXEQmQyl1EJEAqdxGRAKncRUQCFKnczWyQmZWb2Tozm1TP+lZm9lJs/XtmVpDooCIiEl3ccjezNOA5oAToCYw0s551ht0F7HT3bsDPgKcSHVRERKKLcubeF1jn7uvd/SAwF7ixzpgbgTmx6VeAfzEzS1xMERFpiCjlngt8WWt+c2xZvWPcvQrYDbRLREAREWm49Ahj6jsD95MYg5mNA8bFZg+Y2ccR9t+ctAe2pTpEA7S0vKDMydDS8oIy19Y5yqAo5b4ZyKs13wmoPM6YzWaWDmQDO+puyN1nAjMBzKzM3QujhGwuWlrmlpYXlDkZWlpeUOaTEeWyzAdAdzPrYmanAyOA0jpjSoHvxKZvBd5x92PO3EVEJDninrm7e5WZjQcWAWnA8+6+1symAmXuXgr8Bvidma2j+ox9RFOGFhGRE4tyWQZ3/wPwhzrLHq81vR8Y1sB9z2zg+OagpWVuaXlBmZOhpeUFZW4w09UTEZHw6OcHREQC1OTl3hJ/uiBC5ofM7BMzW2Nmb5tZpI8mNZV4eWuNu9XM3MxS/qmDKJnNbHjseV5rZi8kO2M9eeK9LvLN7E9mtir22hicipy18jxvZluO95Fjq/ZM7HjWmNllyc5YJ0+8vKNiOdeY2XIzuzTZGevJdMLMtcb1MbPDZnZrsrLh7k32h+obsJ8DFwCnAx8BPeuM+TdgRmx6BPBSU2ZKUOZrgdax6X9NZeYoeWPjsoClwAqgsAU8x92BVcDZsflzW0DmmcC/xqZ7Al+kOPO3gMuAj4+zfjDwR6q/p3Il8F4zz9uv1uuhJNV5o2Su9dp5h+r7lrcmK1tTn7m3xJ8uiJvZ3f/k7ntjsyuo/ux/qkR5jgF+BDwN7E9muOOIkvke4Dl33wng7luSnLGuKJkdaBObzubY74MklbsvpZ7vm9RyI/BfXm0F0NbMzk9OumPFy+vuy//5eiD17zsg0nMMMAF4FUjqa7ipy70l/nRBlMy13UX12U+qxM1rZr2BPHdfkMxgJxDlOb4QuNDM3jWzFWY2KGnp6hcl8xTgdjPbTPVZ2oTkRDtpDX2tNyepft9FYma5wM3AjGTvO9JHIRshYT9dkESR85jZ7UAhUNSkiU7shHnN7DSqf6lzTLICRRDlOU6n+tLMNVSfoS0zs0vcfVcTZzueKJlHArPdfbqZXUX1dz8ucfcjTR/vpDS3914kZnYt1eXeP9VZIvg58LC7H072BYmmLveE/XRBEkXJjJkNBCYDRe5+IEnZ6hMvbxZwCbA49uLqAJSa2VB3L0tayqNFfV2scPdDwAYzK6e67D9ITsRjRMl8FzAIwN3/18zOoPr3RVJ9Sel4Ir3WmxMz6wX8Gihx9+2pzhNBITA39t5rDww2syp3n9/ke27imw3pwHqgC///JtTFdcbcz9E3VF9O8Q2SKJl7U31zrXsqs0bNW2f8YlJ/QzXKczwImBObbk/15YN2zTzzH4ExsemLqC5KS/FzXcDxb1AO4egbqu+nMmuEvPnAOqBfqnNGzVxn3GySeEO1Sc/cvQX+dEHEzNOAs4D/jv0feZO7D23GeZuViJkXAdeZ2SfAYWCip/BMLWLm7wOzzOxBqi9vjPHYuzoVzOxFqi9rtY/dB3gCyABw9xlU3xcYTHVh7gXGpiZptQh5H6f6ftwvY++7Kk/xj4lFyJwy+oaqiEiA9A1VEZEAqdxFRAKkchcRCZDKXUQkQCp3EZEAqdxFRAKkchcRCZDKXUQkQP8PW6mdRoGjxbgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['king','queen', 'man', 'woman']  \n",
    "\n",
    "vectors = np.array([[0.6,   0.8], \n",
    "                    [0.8, 0.6],\n",
    "                   [.2,.4],[.4,.2]]\n",
    "                 ) \n",
    "\n",
    "plt.plot(vectors[:,0], vectors[:,1], 'o')  \n",
    "plt.xlim(0, 1.5)  \n",
    "plt.ylim(0, 1.5)  \n",
    "for word, x, y in zip(words, vectors[:,0], vectors[:,1]):  \n",
    "    plt.annotate(word, (x, y), size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples:\n",
    "![](https://www.tensorflow.org/images/linear-relationships.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First things first :\n",
    "\n",
    "**1) Install Gensim: **\n",
    "\n",
    "pip install gensim\n",
    "\n",
    "**  2)  Make sure cython is installed ? **\n",
    "\n",
    "cython -V\n",
    "\n",
    "(if no cython):\n",
    "\n",
    "pip install cython\n",
    "\n",
    "\n",
    "** 3) test (Run the sample code in following cell) **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['will', 'this', 'work?', \"i'm\", 'not', 'sure.', 'if', 'not', 'go', 'to', 'step', '#4', '(above)']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "\n",
    "documents = [\"Will this work?  I'm not sure.  If not go to step #4 (above)\"]\n",
    "\n",
    "#turn document into a list of words, remove puncutation\n",
    "texts = [[word for word in document.lower().split()]\n",
    "         for document in documents]\n",
    "\n",
    "print (texts)\n",
    "\n",
    "#train our own model off our small document corpora :(\n",
    "model = gensim.models.Word2Vec(texts, size=100, window=5, min_count=1, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**4) If you see the following error : \"UserWarning: C extension not loaded for Word2Vec\"**\n",
    "\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1.  pip uninstall gensim\n",
    "2.  pip uninstall scipy \n",
    "\n",
    "3. pip install --no-cache-dir scipy==0.15.1\n",
    "4. pip install --no-cache-dir gensim==0.12.1\n",
    "\n",
    "\n",
    "**Refer to the following:** https://groups.google.com/forum/#!topic/gensim/isBqIhrw9mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'Gensim' example: \n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Preprocessing\n",
    "\n",
    "1. Tokenization   \n",
    "2. Remove stop words    \n",
    "3. Convert to lowercase     \n",
    "4. Others: stemming.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# The type of input that Word2Vec is looking for.. \n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "print (texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2: Word Representation\n",
    "\n",
    "Learn a continuous representation of words.\n",
    "Each word (w) is associated with it's own word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim  # using skip-gram\n",
    "\n",
    "model = gensim.models.Word2Vec(texts, size=100, window=5, min_count=1, workers=2, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[See Wiki on arguments](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "A Word2vec model can be trained with hierarchical softmax and/or negative sampling. To approximate the conditional log-likelihood a model seeks to maximize, the hierarchical softmax method uses a Huffman tree to reduce calculation. The negative sampling method, on the other hand, approaches the maximization problem by minimizing the log-likelihood of sampled negative instances. According to the authors, hierarchical softmax works better for infrequent words while negative sampling works better for frequent words and better with low dimensional vectors. As training epochs increase, hierarchical softmax stops being useful.\n",
    "\n",
    "The size of the context window determines how many words before and after a given word would be included as context words of the given word. The recommended value is 10 for skip-gram and 5 for CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', <gensim.models.keyedvectors.Vocab at 0x1a1fa014e0>),\n",
       " ('machine', <gensim.models.keyedvectors.Vocab at 0x1a1f323518>),\n",
       " ('interface', <gensim.models.keyedvectors.Vocab at 0x1a20850c18>),\n",
       " ('lab', <gensim.models.keyedvectors.Vocab at 0x10d09fc88>),\n",
       " ('abc', <gensim.models.keyedvectors.Vocab at 0x10d09f8d0>),\n",
       " ('computer', <gensim.models.keyedvectors.Vocab at 0x10d0a85f8>),\n",
       " ('applications', <gensim.models.keyedvectors.Vocab at 0x10d0a8ac8>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at vocab\n",
    "list(model.wv.vocab.items())[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.9056784e-04,  2.6331816e-03, -4.5844503e-03,  2.3561271e-03,\n",
       "        4.9920352e-03,  8.6510717e-04, -9.6040225e-04, -1.5680060e-03,\n",
       "       -3.5313703e-03, -1.3062753e-03,  3.2207731e-03, -3.3274919e-03,\n",
       "       -2.6567336e-03,  4.6249432e-03, -4.3160920e-03,  4.1824579e-03,\n",
       "        4.4141030e-03, -1.8255849e-03, -1.7649719e-03, -2.0514419e-03,\n",
       "       -1.5970413e-03, -2.4080781e-04, -1.2689905e-03, -4.1478057e-03,\n",
       "       -4.2156456e-03,  4.7142934e-03, -2.4252262e-03,  1.9159009e-03,\n",
       "        1.5217380e-03, -3.9557791e-03, -3.3369930e-03,  1.9593821e-03,\n",
       "       -4.2326646e-03,  2.7611412e-03,  3.7088827e-03, -4.0809829e-03,\n",
       "        3.8485378e-03, -2.1606151e-03, -1.5226426e-03,  1.7767620e-03,\n",
       "       -3.0476108e-04, -1.2119826e-03, -2.5951511e-03,  2.1766273e-03,\n",
       "       -4.8982706e-03,  2.5002356e-03, -1.0236120e-03,  3.4836340e-03,\n",
       "        4.5883209e-03, -1.9338509e-03,  2.2743291e-03,  2.1312912e-03,\n",
       "        8.1261771e-04, -5.1826652e-04,  4.8021958e-03,  2.5840544e-03,\n",
       "       -2.7738954e-03, -1.2568493e-03,  1.9061750e-03,  1.9408258e-03,\n",
       "       -2.7190764e-03, -1.6602994e-03, -3.6392454e-04,  3.1896115e-03,\n",
       "        1.4943709e-03,  2.6032829e-03,  3.1360320e-04,  3.0270498e-03,\n",
       "        2.9490741e-03, -1.9643377e-03, -2.6502500e-03, -1.4519179e-03,\n",
       "        2.9255250e-03,  1.1423385e-04, -1.1164844e-03, -1.8775811e-03,\n",
       "       -1.9832978e-03, -4.0218770e-03,  2.2604149e-03,  2.3343470e-03,\n",
       "       -4.2669498e-03,  3.0297376e-03,  1.0398212e-03,  2.2972168e-03,\n",
       "        4.4181040e-03,  2.2596561e-03, -5.0082534e-05, -4.9576769e-03,\n",
       "       -2.4894197e-03, -3.9227917e-03,  3.5837367e-03,  1.3519273e-03,\n",
       "        2.9711055e-03,  2.8572333e-04, -4.8469771e-03,  3.4702716e-03,\n",
       "        4.1044862e-03,  3.7776802e-03, -5.0157309e-04, -4.9259509e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  and voila, we have our word vector \n",
    "model['trees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What do we have? Word Embeddings \n",
    "\n",
    "**A word embedding W : words → ℝn **\n",
    "\n",
    "The output above is the result of 'word' projections in a latent space\n",
    "of N dimensions, (N ~ size of NN layer we chose).     \n",
    "Our float values above represent the coordinates for the word 'computer' in our 100-dimensional space!\n",
    "\n",
    "Our high dimensional vectors stand in place for words.    \n",
    "Note, that these dimensions are encoding 'latent' properties for 'computer' (such that 'queen' will be geometrically closer to 'king' than it would to be to (let's say) 'computer'. \n",
    "\n",
    "Word Embeddings are useful because:\n",
    "\n",
    "1.  We can measure the semantic similarity between two words\n",
    "2.  We can use these word vectors as features for various NLP supervised learning tasks (such as classification, sentiment analysis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-Gram Methods: \n",
    "\n",
    "#### Skip-Gram example sentence:\n",
    "\n",
    ">\"We are on the cusp of deep learning for the masses\"\n",
    "\n",
    "For Context Window = 2:\n",
    "\n",
    "*We could get the following training examples: (Where target word is __bolded__) *\n",
    "\n",
    "\n",
    "__We__ are on \n",
    "\n",
    "We __are__ on the\n",
    "\n",
    "We are __on__ the cusp\n",
    "\n",
    "\n",
    "#### What's happening underneath the hood?:\n",
    "We have input of skip-gram is a single word (Wi) **'learning'**, we will determine the probability of seeing the words (Wo) : 'of','deep', 'for','the'.\n",
    "\n",
    "1. Transform our vobabulary into a 'bag of indices'\n",
    "\n",
    "2. One-hot encode (input vectors) \n",
    "\n",
    "3. Randomly initialize the Weight Vectors\n",
    "\n",
    "4. Get dot product: (Input vector.InputWeightMatrix) ~ (this is just the weight vector for 'learning')\n",
    "\n",
    "5. Get dot product:  ('learning' weight vector).(Output Weight Matrix) \n",
    "\n",
    "6. Calculate Softmax probabilities:\n",
    "    - What is the probability of 'seeing' the word 'deep' given that we've seen the word 'learning'?  -- >  Using SGD together with softmax regression, we will maximize the probability for 'deep' \n",
    "    - P(Wo|Wi) = (exp(Wi.Wo)/ sum(exp(Wi.Woj)   (sum~ sum of all Woj for all j in Vocabulary)\n",
    "\n",
    "7. As always, we update our Weight matrix to reduce our errors:\n",
    "    - Wi=Wi-a*ej*Wo\n",
    "\n",
    "8. Repeat...\n",
    "\n",
    "\n",
    "<img src='img/skip_gram.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### CBOW: \n",
    "\n",
    "\n",
    "CBOW: very similiar model with the inputs & outputs reversed.  The input layer consists of our word window \n",
    "\n",
    "<img src='img/CBOW.png'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's work with a corpus from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Use Scroll bar with NLTK download... or else?\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build corpus from \n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop+=['?','!','.',',',':',';']\n",
    "\n",
    "#[\n",
    "#\"weren't\",\n",
    "# 'won',\n",
    "# \"won't\",\n",
    "# 'wouldn',\n",
    "# \"wouldn't\",\n",
    "# '?',\n",
    "# '!',\n",
    "# '.',\n",
    "# ',',\n",
    "# ':',\n",
    "# ';']\n",
    "\n",
    "#creating our iterator\n",
    "\n",
    "\n",
    "# An Illustration.. \n",
    "\n",
    "import os\n",
    "\n",
    "class MySentences(object):\n",
    "    # a memory-friendly way to load a large corpora\n",
    "     def __init__(self, dirname):\n",
    "            self.dirname = dirname\n",
    " \n",
    "     def __iter__(self):\n",
    "        # iterate through all file names in our directory\n",
    "         for fname in os.listdir(self.dirname):\n",
    "                for line in open(os.path.join(self.dirname, fname), encoding=\"ISO-8859-1\"):\n",
    "                    word=line.lower().split()\n",
    "                    if word not in stop:\n",
    "                        yield word\n",
    "\n",
    "sentences = MySentences('/Users/timrand/nltk_data/corpora/gutenberg') \n",
    "model = gensim.models.Word2Vec(sentences,size=100,min_count=3,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the following examples aren't great: the modeling is learning from a small dataset of gutenberg books. We'll use a better model in the next section with superior results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('door,', 0.9188751578330994),\n",
       " ('gate', 0.8850337862968445),\n",
       " ('top', 0.871757984161377),\n",
       " ('mount', 0.8664511442184448),\n",
       " ('window', 0.8628943562507629),\n",
       " ('table,', 0.8590527772903442),\n",
       " ('window,', 0.8446979522705078),\n",
       " ('cloud', 0.8374819159507751)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('door' ,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('plate', 0.9383689761161804),\n",
       " ('floor,', 0.937893271446228),\n",
       " ('rock,', 0.9336166381835938),\n",
       " ('paper', 0.9298900961875916),\n",
       " ('crowd', 0.9280639886856079),\n",
       " ('temple.', 0.9261654615402222),\n",
       " ('carrying', 0.925046443939209),\n",
       " ('advancing', 0.9244281649589539),\n",
       " ('contents', 0.9243518114089966),\n",
       " ('neck', 0.9242267608642578)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity\n",
    "\n",
    "model.most_similar('rock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `n_similarity` (Method will be removed in 4.0.0, use self.wv.n_similarity() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87206644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine_similarity\n",
    "\n",
    "#takes the mean and then the cosine distance\n",
    "model.n_similarity(['bread', 'dog'], ['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'explore'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"cat pig dog cow explore\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Data = Better:\n",
    "#### Let's work with Google's pre-trained [Word2Vect Model](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6e230a00a763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTKINTER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;31m#/////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-grams-2013.tsv                 movie_reviews.zip\r\n",
      "3-grams-2013.tsv.gz              \u001b[1m\u001b[36mstopwords\u001b[m\u001b[m\r\n",
      "PubMed-w2v.bin                   stopwords.zip\r\n",
      "\u001b[1m\u001b[36mbrown\u001b[m\u001b[m                            \u001b[1m\u001b[36mtreebank\u001b[m\u001b[m\r\n",
      "brown.zip                        treebank.zip\r\n",
      "\u001b[1m\u001b[36mgoogle_news\u001b[m\u001b[m                      wikipedia-pubmed-and-PMC-w2v.bin\r\n",
      "\u001b[1m\u001b[36mgutenberg\u001b[m\u001b[m                        \u001b[1m\u001b[36mwords\u001b[m\u001b[m\r\n",
      "gutenberg.zip                    words.zip\r\n",
      "\u001b[1m\u001b[36mmovie_reviews\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/timrand/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "# Setup nltk corpora path and Google Word2Vec location\n",
    "google_vec_file = '/Users/timrand/nltk_data/corpora/PubMed-w2v.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('congress', 0.7604073286056519),\n",
       " ('189th', 0.7538500428199768),\n",
       " ('JSCN', 0.7445378303527832),\n",
       " ('conference', 0.74190354347229),\n",
       " ('forty-fourth', 0.7396146059036255),\n",
       " ('143rd', 0.7380350828170776),\n",
       " ('ESPU', 0.7265064120292664),\n",
       " ('Aaas', 0.7248284220695496)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('meeting' ,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ago2', 0.7537841796875),\n",
       " ('DCL1', 0.7393876314163208),\n",
       " ('Dicer', 0.7200010418891907),\n",
       " ('AGO2', 0.7185648679733276),\n",
       " ('AGO1', 0.7168599963188171),\n",
       " ('pri-miRNA', 0.7079482078552246),\n",
       " ('DICER', 0.7037908434867859),\n",
       " ('CSR-1', 0.697556734085083),\n",
       " ('ASH2L', 0.6961140036582947),\n",
       " ('Exportin-5', 0.6952595710754395),\n",
       " ('Rtf1', 0.6932278871536255),\n",
       " ('GLD-1', 0.6905473470687866),\n",
       " ('pri-miRNAs', 0.6885998845100403),\n",
       " ('Exp5', 0.6876062154769897),\n",
       " ('CHD4', 0.6874486804008484),\n",
       " ('Exportin', 0.68733811378479),\n",
       " ('PAF1', 0.6861715316772461),\n",
       " ('Brd2', 0.6846355199813843),\n",
       " ('AGO4', 0.6834419965744019),\n",
       " ('PHF8', 0.681982696056366),\n",
       " ('Nab2', 0.6811540722846985),\n",
       " ('HEN1', 0.6794799566268921),\n",
       " ('GW182', 0.678023099899292),\n",
       " ('Y14', 0.677935004234314),\n",
       " ('DDX5', 0.6773633360862732),\n",
       " ('MRG15', 0.6767968535423279),\n",
       " ('TRRAP', 0.6749491691589355),\n",
       " ('PABPC1', 0.6745913028717041),\n",
       " ('RITS', 0.6739385724067688),\n",
       " ('Argonaute1', 0.6738437414169312),\n",
       " ('DHX9', 0.6737354397773743),\n",
       " ('bromodomain-containing', 0.6735103130340576),\n",
       " ('Ddx5', 0.6728796362876892),\n",
       " ('Argonaute2', 0.6725881099700928),\n",
       " ('PRP19', 0.6716777682304382),\n",
       " ('Spt6', 0.671208381652832),\n",
       " ('TAF9', 0.671030580997467),\n",
       " ('Nrd1', 0.670723021030426),\n",
       " ('SAP18', 0.6704845428466797),\n",
       " ('PRMT5', 0.6702388525009155)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Levenshtein\n",
    "mols = model.most_similar('DGCR8' ,topn=40)\n",
    "mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniq(mols):\n",
    "    collection = []\n",
    "    for m in mols:\n",
    "        collection.append(m[0].upper())\n",
    "    return set(collection)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WAF1',\n",
       " 'P21/WAF1/CIP1',\n",
       " 'P16(INK4)',\n",
       " 'RB2/P130',\n",
       " 'MDM-2',\n",
       " 'P19(ARF)',\n",
       " 'P16',\n",
       " 'WAF1/P21',\n",
       " 'CYCLIND1',\n",
       " 'P21',\n",
       " 'P21/WAF-1',\n",
       " 'P16(INK4A)',\n",
       " 'P16INK4A',\n",
       " 'P21/WAF1',\n",
       " 'BCL2',\n",
       " 'P14(ARF)',\n",
       " 'P27',\n",
       " 'P33(ING1B)',\n",
       " 'PTEN',\n",
       " 'P16INK4',\n",
       " 'P21(WAF1/CIP1)',\n",
       " 'P14ARF',\n",
       " 'PRB2/P130',\n",
       " 'PRB',\n",
       " 'P21WAF1/CIP1',\n",
       " 'P33ING1B',\n",
       " 'P73',\n",
       " 'P-53',\n",
       " 'HDM2',\n",
       " 'P21(WAF1)',\n",
       " 'SKP2',\n",
       " 'WAF-1',\n",
       " 'MDM2',\n",
       " 'P27(KIP1)',\n",
       " 'NM23-H1',\n",
       " 'E2F-1',\n",
       " 'P21WAF1',\n",
       " 'SURVIVIN',\n",
       " 'E2F1',\n",
       " 'P53',\n",
       " 'P19ARF',\n",
       " '14-3-3SIGMA']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols = model.most_similar('p53' ,topn=60) \n",
    "list(get_uniq(mols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WAF1/CIP1', 0.853065013885498), ('p21(WAF1)', 0.8515006303787231), ('p21(WAF1/CIP1)', 0.8485446572303772), ('p21WAF1/CIP1', 0.8446862101554871), ('p21', 0.8412282466888428), ('p21/WAF1', 0.8362233638763428), ('p21WAF1', 0.8323950171470642), ('p21(Waf1/Cip1)', 0.8149312734603882), ('mdm2', 0.8135080337524414), ('p21Waf1/Cip1', 0.8118418455123901), ('CDKN1A', 0.8110986948013306), ('p21waf1', 0.8036508560180664), ('p21(waf1)', 0.8014034032821655), ('p21(waf1/cip1)', 0.7994927167892456), ('p21(WAF1/Cip1)', 0.799335241317749), ('CIP1/WAF1', 0.7970014214515686), ('GADD45', 0.7946544885635376), ('WAF-1', 0.7945549488067627), ('Waf1', 0.7915790677070618), ('p21Waf1', 0.7897320985794067)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-57224273ea85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#A = delete_replicate_molecules('monkey', mols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelete_replicate_molecules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p53'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPrint_both\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mside_by_side\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-57224273ea85>\u001b[0m in \u001b[0;36mside_by_side\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#out_string = f'{str(A[i][0:])[1:10]:50} {str(self.B):50}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mout_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#for i in delete_replicate_molecules('Dicer', mols):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_string' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def delete_replicate_molecules(query, hits):\n",
    "    collection=[]\n",
    "    for mol in hits:\n",
    "        #versions differ only by capitalization, hyphen\n",
    "        if query.replace('-','').upper() == mol[0].replace('-','').upper():\n",
    "            next\n",
    "        else:\n",
    "            collection.append(mol)\n",
    "    return(collection)\n",
    "        #versions differ only by hyphen\n",
    "    \n",
    "\n",
    "class Print_both():\n",
    "    def __init__(self,A,B, trunc_limit=20):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.trunc_limit = trunc_limit\n",
    "    def side_by_side(self):\n",
    "        a_len = len(A)\n",
    "        b_len = len(B)\n",
    "        if (a_len - b_len) > 0 :\n",
    "            shortest = b_len\n",
    "        else:\n",
    "            shortest = a_len\n",
    "        for i in range(shortest):\n",
    "            self.trunc_limit = 10\n",
    "            print(B)\n",
    "            #out_string = f'{str(A[i][0:])[1:10]:50} {str(self.B):50}'\n",
    "            yield out_string\n",
    "    \n",
    "#for i in delete_replicate_molecules('Dicer', mols):\n",
    "#   print(i)\n",
    "\n",
    "#A = delete_replicate_molecules('monkey', mols)\n",
    "B = delete_replicate_molecules('p53', mols)\n",
    "for i in Print_both(A,B).side_by_side():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timrand/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('miRNA-processing', 0.7470805644989014),\n",
       " ('Ago2', 0.7365443110466003),\n",
       " ('Drosha', 0.7317155599594116),\n",
       " ('DGCR8', 0.7200010418891907),\n",
       " ('dicer', 0.7081758975982666),\n",
       " ('Dicer1', 0.695800244808197),\n",
       " ('DICER', 0.6891276836395264),\n",
       " ('Argonaute2', 0.6797058582305908),\n",
       " ('AGO1', 0.678330659866333),\n",
       " ('pre-let-7', 0.6779454946517944),\n",
       " ('microRNA-processing', 0.6755117774009705),\n",
       " ('AGO2', 0.6681179404258728),\n",
       " ('Argonaute', 0.6662837862968445),\n",
       " ('pri-miRNA', 0.665878176689148),\n",
       " ('DCL1', 0.6606435179710388),\n",
       " ('pri-miRNAs', 0.6571208834648132),\n",
       " ('let-7', 0.6549752950668335),\n",
       " ('Ago1', 0.6528126001358032),\n",
       " ('argonaute-2', 0.6494197845458984),\n",
       " ('Eri1', 0.6480423808097839),\n",
       " ('Dicer-1', 0.6473559141159058),\n",
       " ('Ago2-mediated', 0.6458188891410828),\n",
       " ('Argonaute-2', 0.6450265645980835),\n",
       " ('Dicer-2', 0.6447961330413818),\n",
       " ('CSR-1', 0.6437467336654663),\n",
       " ('Dicer-independent', 0.6418540477752686),\n",
       " ('Dicer-dependent', 0.6350765228271484),\n",
       " ('ta-siRNA', 0.633786678314209),\n",
       " ('RDE-1', 0.6336086988449097),\n",
       " ('piRNA', 0.630939781665802),\n",
       " ('drosha', 0.6298325061798096),\n",
       " ('RNAseIII', 0.6296188831329346),\n",
       " ('PRMT5', 0.6275888681411743),\n",
       " ('ARGONAUTE1', 0.6260889768600464),\n",
       " ('Piwi', 0.6250985860824585),\n",
       " ('QDE-2', 0.6245594024658203),\n",
       " ('Argonautes', 0.6230396032333374),\n",
       " ('AGO4', 0.6228219866752625),\n",
       " ('tankyrase-1', 0.6223272085189819),\n",
       " ('ChMda5', 0.622085690498352),\n",
       " ('RNaseIII', 0.621917724609375),\n",
       " ('Dgcr8', 0.6208438873291016),\n",
       " ('dADAR', 0.6183129549026489),\n",
       " ('Rpl22', 0.6179302930831909),\n",
       " ('Nibbler', 0.616866946220398),\n",
       " ('Rnt1p', 0.6162998676300049),\n",
       " ('Dicer-generated', 0.6148021817207336),\n",
       " ('decapping', 0.6140260696411133),\n",
       " ('RHAU', 0.613455057144165),\n",
       " ('argonaute', 0.6134158372879028)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Dicer' ,topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_similarity(['king', 'man'], ['queen', 'woman'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other very cool methods!:      \n",
    "\n",
    "\n",
    "Doc2Vec extends the word2vec algorithm to larger blocks of texts (paragraphs, documents, articles):    \n",
    "- https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "- http://learningaboutdata.blogspot.com/2014/06/plotting-word-embedding-using-tsne-with.html\n",
    "- https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- https://www.tensorflow.org/tutorials/word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some things to keep in Mind when using Word2Vec:\n",
    "\n",
    ">Word2vec requires a lot of data (millions of words +) to train!\n",
    "\n",
    ">However, you can download pretrained vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "- Visualize word vectorization\n",
    "- Prepare gensim environment\n",
    "- Fit word2vec models\n",
    "- Interpret latent variables/vectors (at a theoretical level)\n",
    "- Find similar words and word pairs\n",
    "- Use externally-trained matrices of latent features"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": false,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
